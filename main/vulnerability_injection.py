import pandas as pd
import requests
import time
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_ollama import OllamaLLM
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain.chains.retrieval_qa.base import RetrievalQA
from langchain.prompts import PromptTemplate
import drive
import json
import os
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
logging.basicConfig(level=logging.INFO)

class ContextLoader():
    def __init__(self, context_file_path, github_token):
        self.context_file_path = context_file_path
        self.github_token = github_token
        self.header = {'User-Agent': 'Mozilla/5.0'}

    def load_context_url(self): 
        with open(self.context_file_path, "r") as f: 
            lines = f.read().splitlines()
        self.context_df = pd.DataFrame(lines, columns=["context"])

    def transform_into_raw_url(self): 
        self.context_df["context"] = self.context_df["context"].str.strip().replace(
            "https://github.com/", "https://raw.githubusercontent.com/").str.replace("/blob/", "/", regex=False)

    def get_context_text(self, url): 
        self.header["Authorization"] = f"token {self.github_token}"

        try: 
            response = requests.get(url, headers=self.header)
            response.raise_for_status()
            return url, response.text

        except Exception as e:
            logging.error(f"Error getting link {self.context_df}: {e}")
            return url, None

    def get_context_parallel(self, max_workers=10): 
        urls = [u.strip() for u in self.context_df["context"].tolist() if u.strip()]
        self.Context_store = dict()

        with ThreadPoolExecutor(max_workers=max_workers) as pool: 
            futures = [pool.submit(self.get_context_text, url) for url in urls] 

            for future in as_completed(futures): 
                url, text = future.result()
                if text is not None:
                    self.Context_store[url] = text
        logging.info(f"Fetched: {len(self.Context_store)} / {len(urls)} files")

    def create_context_info(self): 
        text = []

        for url in self.Context_store.keys(): 
            vul_type = url.split("/")[-1].replace("%20", " ")
            text.append(f"Vulnerability Type: {vul_type}\n")
            text.append(self.Context_store[url])

        self.context = "\n\n".join(str(x) for x in text)
        self.context = self.context.encode('latin1', 'ignore').decode('latin1')
    
    def split_context(self): 
        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=300)
        chunks = splitter.create_documents([self.context])
        return chunks
        
class VectorStoreManager():
    def __init__(self, chunks):
        self.chunks = chunks

    def create_vector_store(self, embeddingsModel = "all-MiniLM-L6-v2"): 
        embedding = HuggingFaceEmbeddings(model_name= embeddingsModel)
        similarChunks = FAISS.from_documents(self.chunks, embedding)
        return similarChunks
    

class LangchainQA_Chain(): 
    def __init__(self, similarChunks):
        self.similarChunks = similarChunks

    def build_QA_Chain_with_langchain(self):   
        template = """
    Use the following context containing examples of vulnerable code to help you generate a realistic VCC, but do not copy any code from the context. Instead, use it to understand the patterns and types of vulnerabilities that exist and can be injected in the code:
    ----START OF CONTEXT
    {context}
    ----END OF CONTEXT

    Now, based on the context provided, answer the following question in detail:

    {question}
    """
        prompt = PromptTemplate(
                input_variables=["context", "question"],
                template=template, 
            )
        llm = OllamaLLM(model="qwen2.5-coder:3b")

        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            retriever=self.similarChunks.as_retriever(search_type="similarity", k=3),
            chain_type="stuff",
            chain_type_kwargs={"prompt": prompt},
            return_source_documents=False, 
            verbose= True
        )
        return qa_chain

class ProcessCommits(): 
    def __init__(self, links,  qa_chain, github_token):
        self.qa_chain = qa_chain
        self.links = links
        self.github_token = github_token

    def process_commit(self, commit_link):
        # raw_patch = get_context_text([commit_url], github_token)[commit_url].strip()
        raw_patch = requests.get(commit_link, headers= {
            "User-Agent": "Mozilla/5.0",
            "Authorization": f"token {self.github_token}"
        })

        
        query = (
            "INTRODUCE a realistic NEW vulnerability to the code provided. As in change safe code to vulnerable code."
            "DO so in a flow type way such as what you see in the context, not single-line unsafe filters. "
            "Explain in detail and provide a git diff with + and - of how you made the code vulnerable: "
            f"This is my original code that I want to be converted into a vulnerable code commit: {raw_patch.text}"
            "Only modify the code where you are adding the NEW vulnerabilities."
        )

        for i in range(3): 
            try: 
                result = self.qa_chain.invoke(query)
                time.sleep(2)
                break 
            except Exception as e: 
                if i == 2:
                    logging.error(f"Error in qa_chain.invoke: {e}")
        answer = result.get("result") if isinstance(result, dict) else result

        return f"Commit Link: {commit_link}\n\n" + answer

    def process_parallel_commit(self): 
        answers = []
        
        max_workers = 2

        with ThreadPoolExecutor(max_workers=max_workers) as pool: 
            future_to_link = {pool.submit(self.process_commit, link): 
                            link for link in self.links}
            for future in as_completed(future_to_link):
                link = future_to_link[future]
                try:
                    answer = future.result()
                    answers.append(answer)
                    logging.info(f"✅ Finished {link}")
                except Exception as e:
                    logging.info(f"❌ Error on {link}: {e}")
        return answers

class UploadToDrive(): 
    def __init__(self, answers, drive_folder_id):
        self.answers = answers
        self.drive_folder_id = drive_folder_id

    def upload_answers(self):
        if not self.answers:
            logging.error("No answers to upload.")
            return

        file_name = "response.txt"
        file_path = os.path.join(os.getcwd(), file_name)
        drive_service = drive.get_drive_service()

        initial_doc_name = drive.get_next_filename("Prompt", self.drive_folder_id, drive_service)
        initial_doc_num = int(initial_doc_name.split("Prompt ")[-1]) if initial_doc_name else 1

        cnt = 0
        for answer in self.answers:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(answer)

            drive.upload_and_convert_to_gdoc(
                path=file_path,
                name=f"Prompt {initial_doc_num + cnt}",
                folder_id= self.drive_folder_id,
                drive_service=drive_service,
            )
            cnt += 1
            os.remove(file_path)

class ConfigLoader(): 
    def __init__(self, config_FilePath):
        self.cfg = json.load(open(config_FilePath))
        self.app_cfg = self.cfg["app"]
    @property
    def context_file_path(self): 
        return self.app_cfg["context_file_path"]
    @property
    def input_links(self): 
        with open(self.app_cfg["input_links_file"], "r") as f: 
            links = [l.strip() for l in f if l.strip()]
        return links
    @property
    def drive_folder_id(self):
        return self.app_cfg["drive_folder_id"]
    @property
    def github_token(self): 
        return self.app_cfg["github_token"]




 
def main(): 
    config = ConfigLoader("credentials.json")

    contextLoader = ContextLoader(config.context_file_path, config.github_token)
    contextLoader.load_context_url()
    contextLoader.transform_into_raw_url()
    contextLoader.get_context_parallel()
    contextLoader.create_context_info()
    chunks = contextLoader.split_context()

    similarChunks = VectorStoreManager(chunks).create_vector_store()

    qa_chain = LangchainQA_Chain(similarChunks).build_QA_Chain_with_langchain()
    _1_dfs = qa_chain.invoke("warmup")

    processCommits = ProcessCommits(config.input_links, qa_chain, config.github_token)
    answers = processCommits.process_parallel_commit()
    logging.info(f"Total answers generated: {len(answers)}")

    uploadToDrive = UploadToDrive(answers, config.drive_folder_id)
    uploadToDrive.upload_answers()


if __name__ == '__main__':
    main()